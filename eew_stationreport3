#!/usr/bin/env python

# Calculate some station metrics - noise floor, power at different frequencies, Nspikes...


# Generate a lock file in /tmp so that only one instance of eew_stationreport can run.

import os
import sys

pid = str(os.getpid())
pidfile = "/tmp/eew_stationreport.lockfile"

#if os.path.isfile(pidfile):
#    print ("%s exists.  Exiting." % pidfile)
#    sys.exit()
#else:
#    file = open(pidfile, 'w')
#    file.write(pid)
#    file.close()

# import std packages
from collections import Counter
import datetime
from datetime import timedelta
import glob
import timeit
import fileinput
from collections import OrderedDict

# import third party packages
import numpy as np
from obspy.clients.fdsn import Client
from obspy import UTCDateTime
from obspy.signal.trigger import classic_sta_lta
from obspy import Stream
try:
    from ConfigParser import SafeConfigParser
except:
    from configparser import SafeConfigParser

from jinja2 import Environment, FileSystemLoader, select_autoescape
from weasyprint import HTML

# import station_metrics packages
from station_metrics.io.get_data_metadata import download_fdsn_bulk
from station_metrics.io.get_data_metadata import download_metadata_fdsn
from station_metrics.io.external2 import latency_gaps_completeness

from station_metrics.metrics.preprocessing import raw_trace_to_ground_motion_filtered_pruned
from station_metrics.metrics.noise_metrics import noise_floor, count_peaks_stalta
from station_metrics.metrics.noise_metrics import duration_exceed_RMS

from station_metrics.plotting.plot_eew_stationreport import make_station_figure_eew_stationreport

from config.parse_and_validate_args import validate_args_and_get_times, parse_args

# define how many days we want latency info for (at most)
MAX_LATENCY_DAYS = 14


# define which channel codes denote acceptable seismic channels
SEISMIC_CHANNELS = ['BHE', 'BHN', 'BHZ', 'HHE', 'HHN', 'HHZ',
                    'BH1', 'BH2', 'BH3', 'HH1', 'HH2', 'HH3',
                    'ENE', 'ENN', 'ENZ', 'HNE', 'HNN', 'HNZ',
                    'EN1', 'EN2', 'EN3', 'HN1', 'HN2', 'HN3']
# define a few SOH channels we might be interested in
SOH_CHANNELS = ['LCQ', 'LCE']

THRESHOLD = { 
             'lcq':60,               # minimum quality=60, read Q330 manual
             'lce':5000,             # maximum phase(drift)=5000 microseconds
             'percent_latency_good':98,          # good=maximum latency 3.5s between now and middle of packet
             'percent_completeness':98,          
             'gaps_per_hour':1,	     # maximum number of gaps per hour
             'rms_noise':0.0007,     # maximum RMS amplitude 0.07 cm/s^2 
             'spikes' : 0.0034       # maximum spike amplitude 0.34 sm/s^2
            }

if __name__ == "__main__":
    """
        Generates Phase1 Station Acceptance Report.
        Requirements:
            config/config.eew_stationreport --> configuring the metrics
            command-line arguments --> specify station and time period
    """
    # prepare report engine (jinja2)
    env = Environment(
        loader=FileSystemLoader("./templates"),
        autoescape=select_autoescape(['html', 'htm', 'xml'])
    )
    template = env.get_template('phase1.htm')
        
    #----- Read Processing parameters from a config file
    
    parser = SafeConfigParser()
    parser.read("config/config.eew_stationreport")
    
    FDSNtimeout = float(parser.get('SectionOne','FDSNtimeout'))
    tpadding = float(parser.get('SectionOne','tpadding'))
    sta = float(parser.get('SectionOne','sta'))
    lta = float(parser.get('SectionOne','lta'))
    tbuffer = sta + lta
    freqBP1 = float(parser.get('SectionOne','freqBP1'))
    freqBP2 = float(parser.get('SectionOne','freqBP2'))
    freqBP3 = float(parser.get('SectionOne','freqBP3'))
    freqBP4 = float(parser.get('SectionOne','freqBP4'))
    freqHP = float(parser.get('SectionOne','freqHP'))
    mpd = float(parser.get('SectionOne','mpd'))
    minSTALTAlen = float(parser.get('SectionOne','minSTALTAlen'))
    RMSlen = float(parser.get('SectionOne','RMSlen'))
    GainOrFullResp = parser.get('SectionOne','GainOrFullResp')
    sniffwave_tally_duration = int(parser.get('SectionOne','sniffwave_tally_duration'))
    #PSDperiods = (parser.get('SectionOne','PSDperiods'))[1:-1].split(",")
    #PSDperiods = [float(i) for i in PSDperiods]

    #----- command-line arguments specify what data to get and where
    # options that influence program structure:
    # infile: 
    #     multiple channels, possibly from multiple stations, are defined in an input file. 
    # command-line arguments -N network, -S station:
    #     eew_stationreport is run for the channels of a single station only.
    
    args = parse_args()
    [starttime, endtime, durationinhours, durationinsec] = validate_args_and_get_times(args)
    starttime = starttime.replace(microsecond=0)
    endtime = endtime.replace(microsecond=0)
    nowtime = datetime.datetime.now()
    DateLabel = str(nowtime.strftime('v%Y-%m-%dT%H-%M'))

    # get data from a little before starttime to remedy edge effects
    request_starttime = starttime - datetime.timedelta(0,lta+tpadding)
    duration_padded = durationinsec + sta + lta + (2*tpadding)
    request_endtime = starttime + datetime.timedelta(seconds=duration_padded)

    slice_starttime = starttime - datetime.timedelta(seconds=lta)
    slice_endtime = starttime + datetime.timedelta(seconds=(durationinsec + sta))

    endminusstarttime = (endtime - starttime).total_seconds()
    if ( endminusstarttime < minSTALTAlen ):
        print ("EXITING: requested time is too short or wrong " + str(starttime) + " to " + str(endtime) )
        sys.exit()

    # find out where output reports go
    if not "REPORT_DIR" in os.environ:
        report_dir = "./"

#    save for later, not needed now (decided to dump it all into report_dir)
#    # create report directories if they don't exist yet
#    if not os.path.exists(report_dir+"/html"):
#        try:
#            os.makedirs(report_dir + "/html")
#        except Exception as e:
#            print("Error creating output directory: {}".format(e))
#            sys.exit(1)
#
#    if not os.path.exists(report_dir+"/pdf"):
#        try:
#            os.makedirs(report_dir + "/pdf")
#        except Exception as e:
#            print("Error creating output directory: {}".format(e))
#            sys.exit(1)

    if not os.path.isdir(report_dir):
        print("Error: {} exists but does not appear to be a directory")
        sys.exit(1)

    infile = args.infile
    if infile:
        network = None
        station = None
    else: 
        network = args.network.upper()
        station = args.station.upper()
    datacenter = args.datacenter.upper()
    institution = args.institution
    email = args.email
    iplot = args.iplot
    latency_dir = args.lat_dir
    filelist = []
    if latency_dir:
        # make sure this exists and is readable
        startday = starttime.replace(hour=0,minute=0,second=0)
        if ( starttime.hour == 0 and starttime.minute <= np.ceil(sniffwave_tally_duration/60) + 1 ):
            startday = startday - timedelta(days=1) 
        endday = endtime.replace(hour=0,minute=0,second=0)
        try:
            # assume files are named YYYY_MM_DD_*.csv
            filelistall = []
            if ( institution is None ):
                filelistall = glob.glob(latency_dir + "/*tally.csv")
            else:
                filelistall = glob.glob(latency_dir + "/*tally." + institution + ".csv")
#                filelistall.extend(glob.glob(latency_dir + "/*tally." + institution.upper() + ".csv"))
#                filelistall.extend(glob.glob(latency_dir + "/*tally." + institution.lower() + ".csv"))
            # only read sniffwave_tally files in the timerange being measured

            for ifile in range(0,len(filelistall)):
               filedate = datetime.datetime.strptime(filelistall[ifile].split("/")[-1].split("_")[0], '%Y-%m-%d')
               if ( filedate >= startday and filedate <= endday ):
                   filelist.append(filelistall[ifile])
            filelist = sorted(filelist)
        except Exception as e:
            print("Error creating list of sniffwave_tally output files: {}".format(e))
    if len(filelist) > 0:
        all_latency_metrics = latency_gaps_completeness(filelist,starttime,endtime) 
    else:
        all_latency_metrics = None


    scnl = "UW.LCW2.--.ENZ"
    print (" " )
    print ( all_latency_metrics["UW.LCW2.--.ENZ"] )
    print (" " )
    print ( all_latency_metrics["UW.LCW2.--.ENN"] )
    print (" " )

    print ( all_latency_metrics["UW.LCW2.--.ENE"] )
    print (" " )


            # add latency, gaps, completeness derived from sniffwave, if requested.
#            latency_metrics = OrderedDict()
#            for scnl in channel_metrics:
#                if all_latency_metrics and scnl in all_latency_metrics:
#                    l = all_latency_metrics[scnl]
#                    latency_metrics[scnl] = {}
#                    latency_metrics[scnl]["measurement_start"] = l["measurement_start"].replace(microsecond=0)
#                    latency_metrics[scnl]["measurement_end"] = l["measurement_end"].replace(microsecond=0)
#                    latency_metrics[scnl]["window_length"] = datetime.timedelta(seconds=l["data_timewindow_length"])
#                    latency_metrics[scnl]["acceptable_latency"] = \
#                        (l["percent_latency_good"], "pass" if l["percent_latency_good"] >= 98 else "fail")
#                    latency_metrics[scnl]["gaps_per_hour"] = \
#                        (l["gaps_per_hour"], "pass" if l["gaps_per_hour"] < 1 else "fail")
#                    latency_metrics[scnl]["completeness"] = \
#                        (l["percent_completeness"], "pass" if l["percent_completeness"] >= 98 else "fail")
#                    latency_metrics[scnl]["completeness_incl_penalty"] = \
#                        (l["percent_completeness_w_penalty"], "pass" if l["percent_completeness_w_penalty"] >= 98 else "fail")


